{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simpleConv_TADcnn_CN_MP_same.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjcbGHK91pyf",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Network example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Almrw48o1t_S",
        "colab_type": "text"
      },
      "source": [
        "<p>\n",
        "Marie Zufferey<br>\n",
        "CAS Data science - Machine learning project with TensorFlow<br>\n",
        "February 2019\n",
        "</p>\n",
        "\n",
        "CN1 => 16 kernels of size 3\n",
        "\n",
        "MP1 => stride 2, MP 2\n",
        "\n",
        "CNfinal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbYvlmO32Jzp",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRb2jJp32Ge6",
        "colab_type": "code",
        "outputId": "3bbb7716-9fef-4066-a147-5bfccc8ff6db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "# !!! HARD-CODED INPUT FOLDER NAMES HERE !!!\n",
        "! tar -xzvf myutils.tar.gz\n",
        "#! tar -xzvf random_chromo_data.tar.gz\n",
        "! tar -xzvf cnn_data.tar.gz\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipyd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# We'll tell matplotlib to inline any drawn figures like so:\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from myutils import gr_disp\n",
        "from myutils_v2 import *\n",
        "from my_cnn_functions import *\n",
        "\n",
        "\n",
        "# for online def of nested dict\n",
        "from collections import defaultdict\n",
        "nesteddict = lambda : defaultdict(nesteddict)\n",
        "\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "HTML(\"\"\"<style> .rendered_html code { \n",
        "    padding: 2px 5px;\n",
        "    color: #0000aa;\n",
        "    background-color: #cccccc;\n",
        "} </style>\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "myutils/\n",
            "myutils/gr_disp.pyc\n",
            "myutils/__init__.py\n",
            "myutils/inception.py\n",
            "myutils/__init__.pyc\n",
            "myutils/gr_disp.py\n",
            "cnn_data/\n",
            "cnn_data/GM12878_chr10_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr11_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr12_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr13_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr14_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr15_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr16_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr17_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr18_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr19_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr1_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr20_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr21_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr22_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr2_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr3_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr4_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr5_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr6_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr7_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr8_final_agg_fltrd.txt\n",
            "cnn_data/GM12878_chr9_final_agg_fltrd.txt\n",
            "input: \t1 x 12 x 1\n",
            "in_width: \t1\n",
            "out_width: \t1.0\n",
            "output: \t1.0 x 12.0 x 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style> .rendered_html code { \n",
              "    padding: 2px 5px;\n",
              "    color: #0000aa;\n",
              "    background-color: #cccccc;\n",
              "} </style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs44aZOSiVO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_minibatches=10\n",
        "n_epochs=100\n",
        "minibatch_size=10\n",
        "n_samples_valid=1000\n",
        "\n",
        "bin_seq_len=100\n",
        "\n",
        "valid_ratio=0.2\n",
        "train_ratio=0.8\n",
        "\n",
        "epoch_out_step = 20 # at which step to display\n",
        "learning_rate = 0.001\n",
        "\n",
        "image_file = \"CN_MP_same_nMB\" + str(n_minibatches) + \"_sizeMB\" + str(minibatch_size) +\\\n",
        "              \"_nE\" + str(n_epochs) + \"_nVal\" + str(n_samples_valid) +\\\n",
        "              \"_LR\" + str(learning_rate) + \".png\"\n",
        "\n",
        "log_file = \"CN_MP_same_nMB\" + str(n_minibatches) + \"_sizeMB\" + str(minibatch_size) +\\\n",
        "              \"_nE\" + str(n_epochs) + \"_nVal\" + str(n_samples_valid) +\\\n",
        "              \"_LR\" + str(learning_rate) + \"_log.txt\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbDBa5RM2PhE",
        "colab_type": "text"
      },
      "source": [
        "## 2. Prepare input data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdWZbd8S2Kzx",
        "colab_type": "code",
        "outputId": "6b0564b1-2533-4b00-818d-aabce1b5d66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "### HARD-CODED SETTINGS FOR THE INPUT DATA:\n",
        "\n",
        "input_folder = \"cnn_data\"\n",
        "\n",
        "model_logfile = \"train_model_logfile_trueData.txt\"\n",
        "\n",
        "\n",
        "\n",
        "chromo_pattern = '.*(chr.+)[_\\\\.].*'\n",
        "col_with_BD_score = 0 # the boundary score is held in the 1st column of the DF\n",
        "print(\"! hard-coded chromo_pattern = \" + chromo_pattern)\n",
        "print(\"! hard-coded col_with_BD_score = \" + str(col_with_BD_score))\n",
        "\n",
        "\n",
        "print(\"! hard-coded bin_seq_len = \" + str(bin_seq_len))\n",
        "print(\"! hard-coded valid_ratio = \" + str(valid_ratio))\n",
        "print(\"! hard-coded train_ratio = \" + str(train_ratio))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "! hard-coded chromo_pattern = .*(chr.+)[_\\.].*\n",
            "! hard-coded col_with_BD_score = 0\n",
            "! hard-coded bin_seq_len = 100\n",
            "! hard-coded valid_ratio = 0.2\n",
            "! hard-coded train_ratio = 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vau1XOqP2c11",
        "colab_type": "text"
      },
      "source": [
        "### 2a. Load and prepare input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZmKRgUE2f0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_chromo_files = os.listdir(input_folder)\n",
        "\n",
        "# maintain the following variables:\n",
        "# (because I want to store all the data for all chromosomes in a single dataframe but I want\n",
        "# to be able to perform train/validation separation in a chromosome-specific way)\n",
        "chromos = []\n",
        "chromos_length = {}\n",
        "cumlength = 0\n",
        "chromos_cumlength = {}\n",
        "inputDF = None\n",
        "n_chip = None\n",
        "\n",
        "# derive chromo name from file name\n",
        "for chromo_file in all_chromo_files:\n",
        "  \n",
        "    #print(chromo_file)\n",
        "  \n",
        "    match_chromo = re.match(chromo_pattern, chromo_file)\n",
        "    if match_chromo == None:\n",
        "      continue\n",
        "    curr_chromo = match_chromo.group(1)\n",
        "    chromos.append(curr_chromo)\n",
        "    \n",
        "    #print(\"> \" + chromo_file + \"\\t->\\t\" + curr_chromo)\n",
        "    \n",
        "    chromoDF = pd.read_csv(input_folder + \"/\"+ chromo_file, sep=\"\\t\", header=0)\n",
        "    \n",
        "    #print(chromoDF.iloc[0:5,0:5])\n",
        "    n_bins = chromoDF.shape[0]\n",
        "    \n",
        "    \n",
        "    chromos_length[curr_chromo] = n_bins\n",
        "    chromos_cumlength[curr_chromo] = cumlength\n",
        "    \n",
        "    cumlength += n_bins # update after: cumlength for the first chromo = 0\n",
        "    \n",
        "    \n",
        "    if inputDF is None:\n",
        "      inputDF = chromoDF\n",
        "      n_chip = inputDF.shape[1] - 1\n",
        "    else:\n",
        "      assert chromoDF.shape[1] == inputDF.shape[1]\n",
        "      assert chromoDF.columns.tolist() == inputDF.columns.tolist()\n",
        "      inputDF = inputDF.append(chromoDF)\n",
        "      \n",
        "    #print(\"... n_bins = \" + str(n_bins))\n",
        "    #print(\"... n_chip = \" + str(n_chip))\n",
        "\n",
        "#print(chromos)\n",
        "\n",
        "assert n_chip != None\n",
        "assert not inputDF is None\n",
        "assert cumlength == inputDF.shape[0]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-3rWeZm2idc",
        "colab_type": "text"
      },
      "source": [
        "### 2b. Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFhSuBoi2iml",
        "colab_type": "code",
        "outputId": "4544e268-4fc7-4bab-b697-be54b1274228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "### DATA NORMALIZATION\n",
        "### For the input to the neural network, standardize the columns (mean=0, variance=1)\n",
        "\n",
        "# norm_inputDF = (inputDF-inputDF.mean())/inputDF.std()\n",
        "# corrected: normalize each channel separately\n",
        "norm_inputDF = (inputDF-inputDF.mean(axis=0))/inputDF.std(axis=0)\n",
        "print(norm_inputDF.iloc[0:5,0:5])\n",
        "\n",
        "# chekc data frame column mean and std\n",
        "assert all(norm_inputDF.mean(axis=0) < 1e-10)\n",
        "assert all(norm_inputDF.std(axis=0) - 1 < 1e-10)\n",
        "assert norm_inputDF.shape[1] == len(norm_inputDF.mean(axis=0) < 1e-10)\n",
        "\n",
        "# ensure using only the norm_inputDF later on\n",
        "del inputDF\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   binScore  ENCFF001SUB_ENCFF001XPJ_ENCFF001XPK_CTCF  ENCFF001SUC_EZH2  \\\n",
            "0  0.453783                                 -0.533415         -0.443063   \n",
            "1 -1.120404                                  0.564859         -0.443063   \n",
            "2 -1.125545                                  1.961059          0.107238   \n",
            "3 -1.112067                                  1.604775          0.094801   \n",
            "4 -1.071426                                 -0.378399         -0.443063   \n",
            "\n",
            "   ENCFF001SUD_H2AFZ  ENCFF001SUE_H3K4me1  \n",
            "0          -0.488051            -0.547291  \n",
            "1          -0.488051            -0.547291  \n",
            "2           1.209626             0.705221  \n",
            "3          -0.488051            -0.547291  \n",
            "4          -0.488051            -0.547291  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X7NuFUj2r7k",
        "colab_type": "text"
      },
      "source": [
        "### 2c. Split train and validation data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAbaoP5i2t-t",
        "colab_type": "code",
        "outputId": "2c0be522-1a41-46c7-aa2d-ec88432844c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# for each chromo\n",
        "# a) retrieve # of bins\n",
        "# b) retrieve valid positions (1...chr_len-bin_seq_len +1)\n",
        "# c) set # of train/validation indices to sample\n",
        "# d) random sample the train/validation indices\n",
        "# e) recaste the indices (indices + cumsumlength)\n",
        "# f) append to train/validation input dataset\n",
        "\n",
        "# will store the list of the 1st bin position\n",
        "all_train_indices = [] \n",
        "all_valid_indices = []\n",
        "\n",
        "for chr in chromos:\n",
        "  #print(\"> START prepare data for \" + chr)\n",
        "  # since I want to retrieve a sequence of bins -> need to end before the end of the chromosome...\n",
        "  # and since the norm_inputDF contains all chromos -> need to shift the idx to the start of the chromo  \n",
        "  chr_nbin = chromos_length[chr]\n",
        "  chr_cumlen = chromos_cumlength[chr]\n",
        "  chr_valid_start_positions = list(range(chr_cumlen, chr_nbin + chr_cumlen - bin_seq_len + 1))\n",
        "\n",
        "  assert all((np.array(chr_valid_start_positions) + bin_seq_len) <= (chr_nbin + chr_cumlen))\n",
        "  \n",
        "  # !!! BUT SAMPLES WONT BE INDEPENDENT -> ONE BIN WILL BE IN MANY SAMPLES (not at middle position...)\n",
        "  n_train = int(math.floor(train_ratio * len(chr_valid_start_positions)))\n",
        "  n_valid = int(math.floor(valid_ratio * len(chr_valid_start_positions)))\n",
        "  assert (n_train + n_valid) <= chr_nbin\n",
        "  # shuffle the start indices (NB: not sure it is needed - shuffling also done before iteration over minibatches at each epoch)\n",
        "  tmp = list(chr_valid_start_positions)\n",
        "  random.shuffle(chr_valid_start_positions)\n",
        "  assert tmp != chr_valid_start_positions # ensure shuffle is done in place...\n",
        "  train_indices = chr_valid_start_positions[:n_train]\n",
        "  valid_indices = chr_valid_start_positions[n_train:(n_train + n_valid)]\n",
        "  \n",
        "  #print(\"# of train indices = \" + str(len(train_indices)))\n",
        "  #print(\"# of valid indices = \" + str(len(valid_indices)))\n",
        "   \n",
        "  all_train_indices += train_indices\n",
        "  all_valid_indices += valid_indices\n",
        "\n",
        "  \n",
        "print(\"# of samples = \" + str(norm_inputDF.shape[0]))\n",
        "print(\"# of all_train indices = \" + str(len(all_train_indices)))\n",
        "print(\"# of all_valid indices = \" + str(len(all_valid_indices)))\n",
        "\n",
        "# since I want to retrieve a sequence of bins -> have ended before the end of each chromosome...\n",
        "all_chromo_nbr_invalid_start_positions = (bin_seq_len - 1) * len(chromos)\n",
        "\n",
        "# cannot be tested equal because of the rounding\n",
        "assert (len(all_train_indices) + len(all_valid_indices)) <= (math.floor(train_ratio*\n",
        "                                                                        norm_inputDF.shape[0])+\n",
        "                                                             math.floor(valid_ratio * \n",
        "                                                                        norm_inputDF.shape[0]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of samples = 128394\n",
            "# of all_train indices = 100964\n",
            "# of all_valid indices = 25236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOsWWZZm2yV2",
        "colab_type": "text"
      },
      "source": [
        "## 3. Define helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJYljQA62yh1",
        "colab_type": "text"
      },
      "source": [
        "###3.a. Function to retrieve current dataset to pass to the network for a given minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qrvH8Yu21ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DEFINED IN: my_cnn_functions.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHUY0Lx73CH3",
        "colab_type": "text"
      },
      "source": [
        "### 3.b. Wrapper functions to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9T966Gl3C4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DEFINED IN: my_cnn_functions.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOko9Wrl4ls1",
        "colab_type": "text"
      },
      "source": [
        "## 4. Define the graph* (with graph.as_default(): ... )*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZDQmpkW4l5z",
        "colab_type": "text"
      },
      "source": [
        "###4.a. Hard-coded settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL51Z_4S4o-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## HARD CODED FOR THE INPUT\n",
        "\n",
        "dropout_keep_prob = 1    # no dropout regularization for the moment\n",
        "\n",
        "n_filt=16\n",
        "k_size=1\n",
        "n_stri_conv=1\n",
        "p_type=\"same\"\n",
        "activ_fct=tf.nn.relu\n",
        "mp_size=2\n",
        "n_stri_pool=2\n",
        "\n",
        "bin_seq_len=int(bin_seq_len)\n",
        "n_chip=int(n_chip)\n",
        "\n",
        "# ### CROPPING THE INPUT\n",
        "# if p_type.lower() == \"valid\":\n",
        "#   crop_delta =  k_size//2\n",
        "#   crop_step = (mp_size)**n_MP\n",
        "# elif p_type.lower() == \"same\":\n",
        "#   crop_delta =0\n",
        "#   crop_step = (mp_size)**n_MP\n",
        "# else:\n",
        "#   print(\"invalid p_type\")\n",
        "#   sys.exit(1)\n",
        "\n",
        " \n",
        "# y_input_cropped = y_input[crop_delta:-crop_delta:crop_step]\n",
        "\n",
        "crop_delta =0\n",
        "crop_step=mp_size\n",
        "bin_seq_len_cropped = bin_seq_len//mp_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSgKZIgh4rzZ",
        "colab_type": "text"
      },
      "source": [
        "###4.b. Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIgl5Jm2hcOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E6dhIyx4r-F",
        "colab_type": "code",
        "outputId": "9a454bc9-4af8-432a-9c0f-fc16fd89b3e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"> START constructing TF graph\")\n",
        "\n",
        "g = tf.Graph()\n",
        "\n",
        "print(\"... construct placeholders\")\n",
        "with g.as_default():\n",
        "  \n",
        "\n",
        "  ### DEFINE INPUT PLACEHOLDERS  # -> put None instead of minibatch_size to be run with validation set !!!\n",
        "  x_input = tf.placeholder(dtype = tf.float32, \n",
        "                           shape = [None, bin_seq_len, n_chip],  # [batch_size, sequence_length, num_proteins]\n",
        "                           name = \"x_input\") \n",
        " \n",
        "  ### y_obs need to be the cropped variables !!!!!!! \n",
        "  y_obs = tf.placeholder(dtype = tf.float32, \n",
        "                         shape = [None, bin_seq_len_cropped, 1],  # [batch_size, sequence_length] or [batch_size, sequence_length, 1]\n",
        "                         name  = \"y_obs\")\n",
        "\n",
        "  minibatch_size_ = tf.placeholder(dtype = tf.int32,   # [batch_size, sequence_length] or [batch_size, sequence_length, 1]\n",
        "                         name  = \"minibatch_size_\")\n",
        "\n",
        "  # probability to keep the unit at regularization\n",
        "  drop_keep_prob = tf.placeholder(tf.float32, name=\"drop_keep_prob\")\n",
        "  \n",
        "  # learning rate\n",
        "  learn_rate = tf.placeholder(tf.float32, name =\"learn_rate\")\n",
        "  \n",
        "  ### CALL THE NN TO RETRIEVE THE PREDICTIONS\n",
        "  y_pred =   conv1d_model_CN_MP(CN_input = x_input,\n",
        "                   CN_nbr_filters = n_filt,\n",
        "                   CN_size_kernel = k_size,\n",
        "                   CN_step_stride=n_stri_conv,\n",
        "                   CN_type_padding=p_type,\n",
        "                   CN_activ_function=activ_fct,\n",
        "                  \n",
        "                  MP_mp_size = mp_size,\n",
        "                  MP_step_stride = n_stri_pool,\n",
        "                  MP_type_padding = p_type,\n",
        "                             \n",
        "                  minibatch_size = minibatch_size_,           \n",
        "                  bin_seq_len=bin_seq_len,\n",
        "                  n_chip = n_chip\n",
        "                            )\n",
        "\n",
        "  \n",
        "  ### OPTIMIZATION  \n",
        "  # compute the cost -> linear function with MSE \n",
        "  loss = tf.reduce_mean(tf.square(y_obs - y_pred))\n",
        "\n",
        "  # run the optimizer\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=learn_rate).minimize(loss)\n",
        "\n",
        "  \n",
        "    # for visualization we will calculate the gradients\n",
        "    #gradients of each of bin_seq_len outputs over input x\n",
        "   # yh_grad = [tf.gradients(Y_onehot[..., i], X) for i in range(10)]\n",
        "    #gradient of maximal output over input x\n",
        "    #ym_grad = tf.gradients(tf.reduce_max(Y_onehot, axis=1), X)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> START constructing TF graph\n",
            "... construct placeholders\n",
            "WARNING:tensorflow:From /content/my_cnn_functions.py:100: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv1d instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /content/my_cnn_functions.py:119: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.max_pooling1d instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEC4TLHwFwkF",
        "colab_type": "code",
        "outputId": "f2a64eae-4f30-4df6-d075-f82266775ced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "source": [
        "all_minibatch_avg_loss_train = []\n",
        "all_epoch_loss_train = []\n",
        "all_epoch_loss_valid = []\n",
        "\n",
        "losses_train = []\n",
        "losses_valid = []\n",
        "\n",
        "# Start training\n",
        "with tf.Session(graph=g) as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(tf.global_variables_initializer())\n",
        " \n",
        "    # training in 2 loops: 1) outer: over epochs; 2) for each epoch: over mini-batches (optimization for all of the minin-batches)\n",
        "    # -> at the end of 1 epoch, as many optimization as mini-batches\n",
        "    # !!! data should not go into training pipeline in same order !!!\n",
        "    # -> at the beginning of each epoch, shuffle the indices before iterating over the mini-batches !!!\n",
        "    all_epoch_avg_loss_train = []\n",
        "    all_epoch_avg_loss_valid = []\n",
        "    \n",
        "    # Iteration over the batches\n",
        "    for i_epoch in range(n_epochs):\n",
        "      epoch_avg_loss_train = 0\n",
        "      epoch_avg_loss_valid = 0\n",
        "      \n",
        "      for i_minibatch in range(n_minibatches):\n",
        "        \n",
        "\n",
        "        \n",
        "        minibatch_x, minibatch_y = get_minibatch_xy(index_list=all_train_indices,\n",
        "                                                  i_batch=i_minibatch, \n",
        "                                                  n_to_sample=minibatch_size,\n",
        "                                                  full_inputDF = norm_inputDF,\n",
        "                                                  y_obs_colnbr = col_with_BD_score,\n",
        "                                                  seq_len = bin_seq_len) \n",
        "        x_sequence=minibatch_x\n",
        "\n",
        "        if p_type.lower() == \"same\": \n",
        "          y_input_cropped=np.apply_along_axis(crop_seq, 1, minibatch_y,  mp_step=crop_step, check_size=bin_seq_len_cropped)\n",
        "        else:\n",
        "          print(\"not implemented\")\n",
        "          sys.exit(1)\n",
        "        # sess.run() should be fed with all minibatch samples        \n",
        "        # CALL ONLY THE OPTIMIZER !!! -> IN CASCADE, WILL RUN THE FULL GRAPH\n",
        "        # Run optimization (backprop) # should have as many optimizations as mini-batches \n",
        "        # Fit training using batch data\n",
        "        _, minibatch_loss = sess.run((optimizer, loss),\n",
        "                  feed_dict={\n",
        "                      x_input: x_sequence,\n",
        "                      y_obs: y_input_cropped,\n",
        "                      learn_rate: learning_rate,\n",
        "                                            minibatch_size_ :minibatch_size\n",
        "\n",
        "                      })\n",
        "\n",
        "        loss_train = minibatch_loss\n",
        "        losses_train.append(np.mean(loss_train))\n",
        "                        \n",
        "        x_valid, y_valid = get_minibatch_xy(index_list=all_valid_indices,\n",
        "                                  i_batch=0, \n",
        "                                  n_to_sample=n_samples_valid,  # !!!!!!!!!!!!!!!!!! WRONG HERE BUT I NEED TO UPDATE THE GRAPH MODEL DEFINITION !!!!!!!!!!!!!!!!!!,\n",
        "                                  full_inputDF = norm_inputDF,\n",
        "                                  y_obs_colnbr = col_with_BD_score,\n",
        "                                  seq_len = bin_seq_len)   \n",
        "        \n",
        "        if p_type.lower() == \"same\": \n",
        "          y_valid_cropped=np.apply_along_axis(crop_seq, 1, y_valid,  mp_step=crop_step, check_size=bin_seq_len_cropped)\n",
        "        else:\n",
        "          print(\"not implemented\")\n",
        "          sys.exit(1)\n",
        "          \n",
        "        loss_valid = sess.run((loss),feed_dict={\n",
        "                      x_input: x_valid,\n",
        "                      y_obs: y_valid_cropped,\n",
        "                      learn_rate: learning_rate,\n",
        "                      minibatch_size_: n_samples_valid\n",
        "                      })\n",
        "\n",
        "        \n",
        "        losses_valid.append(np.mean(loss_valid))\n",
        "\n",
        "        txt = \"Epoch: %03d/%03d - minibatch: %03d/%03d,  minibatch_loss_train = %.9f\" % (i_epoch, n_epochs,i_minibatch, n_minibatches, loss_train)\n",
        "        if not i_epoch % epoch_out_step:\n",
        "          print(txt)\n",
        "          print_in_file(mytext=txt, filename=log_file)\n",
        "        \n",
        "        txt = \"Epoch: %03d/%03d - minibatch: %03d/%03d,  minibatch_loss_valid = %.9f\" % (i_epoch, n_epochs,i_minibatch, n_minibatches, loss_valid)\n",
        "        if not i_epoch % epoch_out_step:\n",
        "          print(txt)\n",
        "          print_in_file(mytext=txt, filename=log_file)\n",
        "\n",
        "\n",
        "        # Add current mini-batch loss to average loss for this epoch:\n",
        "        epoch_avg_loss_train += loss_train/n_minibatches\n",
        "        epoch_avg_loss_valid += loss_valid/n_minibatches\n",
        "\n",
        "\n",
        "      # END-For i_minibatch\n",
        "      all_epoch_avg_loss_train.append(epoch_avg_loss_train)\n",
        "      all_epoch_avg_loss_valid.append(epoch_avg_loss_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 000/100 - minibatch: 000/010,  minibatch_loss_train = 5.889060497\n",
            "Epoch: 000/100 - minibatch: 000/010,  minibatch_loss_valid = 4.883594513\n",
            "Epoch: 000/100 - minibatch: 001/010,  minibatch_loss_train = 5.056371689\n",
            "Epoch: 000/100 - minibatch: 001/010,  minibatch_loss_valid = 4.502574921\n",
            "Epoch: 000/100 - minibatch: 002/010,  minibatch_loss_train = 4.776245594\n",
            "Epoch: 000/100 - minibatch: 002/010,  minibatch_loss_valid = 4.207888126\n",
            "Epoch: 000/100 - minibatch: 003/010,  minibatch_loss_train = 6.104215622\n",
            "Epoch: 000/100 - minibatch: 003/010,  minibatch_loss_valid = 3.974621534\n",
            "Epoch: 000/100 - minibatch: 004/010,  minibatch_loss_train = 5.038725376\n",
            "Epoch: 000/100 - minibatch: 004/010,  minibatch_loss_valid = 3.809351921\n",
            "Epoch: 000/100 - minibatch: 005/010,  minibatch_loss_train = 5.798929214\n",
            "Epoch: 000/100 - minibatch: 005/010,  minibatch_loss_valid = 3.690274954\n",
            "Epoch: 000/100 - minibatch: 006/010,  minibatch_loss_train = 4.778449059\n",
            "Epoch: 000/100 - minibatch: 006/010,  minibatch_loss_valid = 3.601022243\n",
            "Epoch: 000/100 - minibatch: 007/010,  minibatch_loss_train = 5.180255413\n",
            "Epoch: 000/100 - minibatch: 007/010,  minibatch_loss_valid = 3.525280714\n",
            "Epoch: 000/100 - minibatch: 008/010,  minibatch_loss_train = 5.070496082\n",
            "Epoch: 000/100 - minibatch: 008/010,  minibatch_loss_valid = 3.449733019\n",
            "Epoch: 000/100 - minibatch: 009/010,  minibatch_loss_train = 3.649853468\n",
            "Epoch: 000/100 - minibatch: 009/010,  minibatch_loss_valid = 3.372622728\n",
            "Epoch: 020/100 - minibatch: 000/010,  minibatch_loss_train = 1.034218431\n",
            "Epoch: 020/100 - minibatch: 000/010,  minibatch_loss_valid = 1.193439722\n",
            "Epoch: 020/100 - minibatch: 001/010,  minibatch_loss_train = 1.041888595\n",
            "Epoch: 020/100 - minibatch: 001/010,  minibatch_loss_valid = 1.192337632\n",
            "Epoch: 020/100 - minibatch: 002/010,  minibatch_loss_train = 1.031747937\n",
            "Epoch: 020/100 - minibatch: 002/010,  minibatch_loss_valid = 1.191301465\n",
            "Epoch: 020/100 - minibatch: 003/010,  minibatch_loss_train = 1.056807160\n",
            "Epoch: 020/100 - minibatch: 003/010,  minibatch_loss_valid = 1.190662384\n",
            "Epoch: 020/100 - minibatch: 004/010,  minibatch_loss_train = 0.930878401\n",
            "Epoch: 020/100 - minibatch: 004/010,  minibatch_loss_valid = 1.190216422\n",
            "Epoch: 020/100 - minibatch: 005/010,  minibatch_loss_train = 0.934193194\n",
            "Epoch: 020/100 - minibatch: 005/010,  minibatch_loss_valid = 1.189197659\n",
            "Epoch: 020/100 - minibatch: 006/010,  minibatch_loss_train = 1.142030239\n",
            "Epoch: 020/100 - minibatch: 006/010,  minibatch_loss_valid = 1.187667727\n",
            "Epoch: 020/100 - minibatch: 007/010,  minibatch_loss_train = 1.037169456\n",
            "Epoch: 020/100 - minibatch: 007/010,  minibatch_loss_valid = 1.186668396\n",
            "Epoch: 020/100 - minibatch: 008/010,  minibatch_loss_train = 0.916439414\n",
            "Epoch: 020/100 - minibatch: 008/010,  minibatch_loss_valid = 1.185756445\n",
            "Epoch: 020/100 - minibatch: 009/010,  minibatch_loss_train = 1.005595207\n",
            "Epoch: 020/100 - minibatch: 009/010,  minibatch_loss_valid = 1.184688091\n",
            "Epoch: 040/100 - minibatch: 000/010,  minibatch_loss_train = 0.877274394\n",
            "Epoch: 040/100 - minibatch: 000/010,  minibatch_loss_valid = 1.069445968\n",
            "Epoch: 040/100 - minibatch: 001/010,  minibatch_loss_train = 0.842845678\n",
            "Epoch: 040/100 - minibatch: 001/010,  minibatch_loss_valid = 1.069000483\n",
            "Epoch: 040/100 - minibatch: 002/010,  minibatch_loss_train = 0.885288298\n",
            "Epoch: 040/100 - minibatch: 002/010,  minibatch_loss_valid = 1.068469405\n",
            "Epoch: 040/100 - minibatch: 003/010,  minibatch_loss_train = 0.848611057\n",
            "Epoch: 040/100 - minibatch: 003/010,  minibatch_loss_valid = 1.068352222\n",
            "Epoch: 040/100 - minibatch: 004/010,  minibatch_loss_train = 0.818087876\n",
            "Epoch: 040/100 - minibatch: 004/010,  minibatch_loss_valid = 1.068488955\n",
            "Epoch: 040/100 - minibatch: 005/010,  minibatch_loss_train = 0.776060283\n",
            "Epoch: 040/100 - minibatch: 005/010,  minibatch_loss_valid = 1.068206668\n",
            "Epoch: 040/100 - minibatch: 006/010,  minibatch_loss_train = 0.908804536\n",
            "Epoch: 040/100 - minibatch: 006/010,  minibatch_loss_valid = 1.067484379\n",
            "Epoch: 040/100 - minibatch: 007/010,  minibatch_loss_train = 0.818356693\n",
            "Epoch: 040/100 - minibatch: 007/010,  minibatch_loss_valid = 1.067275643\n",
            "Epoch: 040/100 - minibatch: 008/010,  minibatch_loss_train = 0.769941151\n",
            "Epoch: 040/100 - minibatch: 008/010,  minibatch_loss_valid = 1.066953421\n",
            "Epoch: 040/100 - minibatch: 009/010,  minibatch_loss_train = 0.847845256\n",
            "Epoch: 040/100 - minibatch: 009/010,  minibatch_loss_valid = 1.066391706\n",
            "Epoch: 060/100 - minibatch: 000/010,  minibatch_loss_train = 0.805994809\n",
            "Epoch: 060/100 - minibatch: 000/010,  minibatch_loss_valid = 1.018055439\n",
            "Epoch: 060/100 - minibatch: 001/010,  minibatch_loss_train = 0.756794393\n",
            "Epoch: 060/100 - minibatch: 001/010,  minibatch_loss_valid = 1.017805338\n",
            "Epoch: 060/100 - minibatch: 002/010,  minibatch_loss_train = 0.807620585\n",
            "Epoch: 060/100 - minibatch: 002/010,  minibatch_loss_valid = 1.017391324\n",
            "Epoch: 060/100 - minibatch: 003/010,  minibatch_loss_train = 0.753720701\n",
            "Epoch: 060/100 - minibatch: 003/010,  minibatch_loss_valid = 1.017498136\n",
            "Epoch: 060/100 - minibatch: 004/010,  minibatch_loss_train = 0.760374308\n",
            "Epoch: 060/100 - minibatch: 004/010,  minibatch_loss_valid = 1.017980576\n",
            "Epoch: 060/100 - minibatch: 005/010,  minibatch_loss_train = 0.709947109\n",
            "Epoch: 060/100 - minibatch: 005/010,  minibatch_loss_valid = 1.017889977\n",
            "Epoch: 060/100 - minibatch: 006/010,  minibatch_loss_train = 0.815181613\n",
            "Epoch: 060/100 - minibatch: 006/010,  minibatch_loss_valid = 1.017070174\n",
            "Epoch: 060/100 - minibatch: 007/010,  minibatch_loss_train = 0.731791079\n",
            "Epoch: 060/100 - minibatch: 007/010,  minibatch_loss_valid = 1.016974092\n",
            "Epoch: 060/100 - minibatch: 008/010,  minibatch_loss_train = 0.702827990\n",
            "Epoch: 060/100 - minibatch: 008/010,  minibatch_loss_valid = 1.016820312\n",
            "Epoch: 060/100 - minibatch: 009/010,  minibatch_loss_train = 0.772873998\n",
            "Epoch: 060/100 - minibatch: 009/010,  minibatch_loss_valid = 1.016436219\n",
            "Epoch: 080/100 - minibatch: 000/010,  minibatch_loss_train = 0.764549077\n",
            "Epoch: 080/100 - minibatch: 000/010,  minibatch_loss_valid = 0.990122974\n",
            "Epoch: 080/100 - minibatch: 001/010,  minibatch_loss_train = 0.713364482\n",
            "Epoch: 080/100 - minibatch: 001/010,  minibatch_loss_valid = 0.990036845\n",
            "Epoch: 080/100 - minibatch: 002/010,  minibatch_loss_train = 0.768104851\n",
            "Epoch: 080/100 - minibatch: 002/010,  minibatch_loss_valid = 0.989755154\n",
            "Epoch: 080/100 - minibatch: 003/010,  minibatch_loss_train = 0.697240949\n",
            "Epoch: 080/100 - minibatch: 003/010,  minibatch_loss_valid = 0.989985406\n",
            "Epoch: 080/100 - minibatch: 004/010,  minibatch_loss_train = 0.731440067\n",
            "Epoch: 080/100 - minibatch: 004/010,  minibatch_loss_valid = 0.990598142\n",
            "Epoch: 080/100 - minibatch: 005/010,  minibatch_loss_train = 0.669342518\n",
            "Epoch: 080/100 - minibatch: 005/010,  minibatch_loss_valid = 0.990605533\n",
            "Epoch: 080/100 - minibatch: 006/010,  minibatch_loss_train = 0.763893783\n",
            "Epoch: 080/100 - minibatch: 006/010,  minibatch_loss_valid = 0.989859819\n",
            "Epoch: 080/100 - minibatch: 007/010,  minibatch_loss_train = 0.675908208\n",
            "Epoch: 080/100 - minibatch: 007/010,  minibatch_loss_valid = 0.989781260\n",
            "Epoch: 080/100 - minibatch: 008/010,  minibatch_loss_train = 0.667079091\n",
            "Epoch: 080/100 - minibatch: 008/010,  minibatch_loss_valid = 0.989638805\n",
            "Epoch: 080/100 - minibatch: 009/010,  minibatch_loss_train = 0.733609855\n",
            "Epoch: 080/100 - minibatch: 009/010,  minibatch_loss_valid = 0.989360809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxU3M25AeY3n",
        "colab_type": "code",
        "outputId": "1d6b453b-4de4-48b3-e50e-15c8e6e9c1eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "source": [
        "# PLOT LOSS    (function defined in my_cnn_functions.py)\n",
        "mytit= \"# MB=%d, # epochs=%d, MB size=%d, # valid=%d - learning rate=%.5f\" % (n_minibatches, n_epochs, minibatch_size, n_samples_valid, learning_rate) \n",
        "\n",
        "loss_plot(train_data=all_epoch_avg_loss_train, valid_data=all_epoch_avg_loss_valid, \n",
        "          plotTit = mytit, image_file = image_file\n",
        "         )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHjCAYAAAA374shAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}