{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial I: Introduction to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Bern Winter School on Machine Learning, 28.01-01.02 2019<br>\n",
    "Mykhailo Vladymyrov\n",
    "</p>\n",
    "\n",
    "This work is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main feature of TF is the way we define operations.\n",
    "In regular programming we define a set of functions or methods on the objects.\n",
    "In TF we define a computational graph. Computational graph is a directed graph in which every node corresponds to an operation or variable. Variables can feed their value into operations, and operations can feed their output into other operations.\n",
    "Then, during execution we feed some data and/or parameters as input of the graph, and the graph produces the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebooks you need Tensorflow and numpy installed.\n",
    "\n",
    "Basic knowledge of Python can be acquired [here](https://docs.python.org/3/tutorial/) and of Numpy [here](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html)\n",
    "\n",
    "Full documentation on Tensorflow functions is available in the [reference](https://www.tensorflow.org/api_docs/python/). Sometimes [functions' implementation](https://github.com/tensorflow/tensorflow) might help to understand what is happening under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Cell execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Press ``Ctrl+Enter`` or ``Shift+Enter`` on the next cell to execute the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('It works')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate between cells with arrows. Press `Enter` to edit cell, `Esc` to exit. Press `a` or `b` too create a new cell above or below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unpack libraries\n",
    "if using colab, upload the `material.tgz` and run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf material.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipyd\n",
    "import tensorflow as tf\n",
    "\n",
    "# We'll tell matplotlib to inline any drawn figures like so:\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from utils import gr_disp\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"<style> .rendered_html code { \n",
    "    padding: 2px 5px;\n",
    "    color: #0000aa;\n",
    "    background-color: #cccccc;\n",
    "} </style>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create our first graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the input for the graph. The easiest way is to define so called ``placeholder``, where during the excecution we will feed in the input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.placeholder(name = 'input', shape=(), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will define two simple operations. In most cases simple Python notation gives the desired result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = input + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = input * out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_disp.show(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session is used to compute the desired outputs, for example our defined ``out1``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res1 = sess.run(out1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you will uncomment and run the above cell, you will get an error, indicating that the value for the ``input`` should be given. Here we will use feed dictionary, where we specify input as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = sess.run(out1, feed_dict={input: 1})\n",
    "print(res1)\n",
    "#out1 = input+5 = 1+5 = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "several values can be computed at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1, res2 = sess.run((out1, out2), feed_dict={input: 3})\n",
    "print(res1, res2)\n",
    "#out1 = input+5 = 3+5 = 8\n",
    "#out1 = (input+5)*input = (3+5)*3 = 8*3=24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">*It is important to remember that in principle its better NOT TO USE ``feed_dict``: it is rather slow. \n",
    "There are several proper built-in mechanisms, that allow smooth data reading, in particular from disc (which is generally super slow!).*</span>\n",
    "\n",
    "While in this course we will keep using ``feed_dict``, since it's more visual, and helps to better understand what is going on, you are highly encouradged to read and follow the official [guidelines](https://www.tensorflow.org/programmers_guide/datasets) related to the data streaming and handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML tasks we often need to perform operations on high-dimensional data. Theese are represented as tensors in TF. For example we can calculate sum of squared values in an 1D array with 5 elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "input_arr = tf.placeholder(name='input_arr', dtype=tf.float32, shape=(5,))\n",
    "squared = tf.multiply(input_arr, input_arr)\n",
    "out_sum = tf.reduce_sum(squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np_arr = np.asarray((1,2,3,4,5), dtype=np.float32)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(out_sum, feed_dict={input_arr: np_arr}))\n",
    "# squared = (1,4,9,16,25)\n",
    "# out_sum = 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can do the same for several 1D arrays at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "input_arr = tf.placeholder(name='input_arr', dtype=tf.float32, shape=(None, 5)) #None stands for unknows length of the array\n",
    "squared = tf.multiply(input_arr, input_arr)\n",
    "out_sum = tf.reduce_sum(squared, axis=1) # sum only along 1st axis\n",
    "\n",
    "#Sample arrays of different size along first axis. \n",
    "#They all can be fed into the input_arr placeholder since along first axis size is unconstrained\n",
    "np_arr1 = np.asarray([[1,2,3,4,5]], dtype=np.float32)\n",
    "np_arr2 = np.asarray([[1,2,3,4,5], [2,3,4,5,6]], dtype=np.float32)\n",
    "np_arr3 = np.asarray([[1,2,3,4,5], [2,3,4,5,6], [25,65,12,12,11], [1,2,3,4,5], [2,3,4,5,6], [25,65,12,12,11]], dtype=np.float32)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(out_sum, feed_dict={input_arr: np_arr1}))\n",
    "    print(sess.run(out_sum, feed_dict={input_arr: np_arr2}))\n",
    "    print(sess.run(out_sum, feed_dict={input_arr: np_arr3}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Excercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: You can use question mark to get description of function right from Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "tf.multiply?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or ``Shift+Tab`` within the brackets to see function parameters (just ``Tab`` for google colab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the code bellow to calculate mean of array's elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... #1. reset the graph\n",
    "input_arr = tf.placeholder(name='input_arr', shape=(None, None), dtype=tf.float32) #None stands for unknows length of the array\n",
    "out_mean = ... # 2.use reduce_mean to claculate mean along specified axes\n",
    "\n",
    "np_arr = np.asarray([[1,2,3,4,5], [2,3,4,5,6], [25,65,12,12,11]], dtype=np.float32)\n",
    "with tf.Session() as sess:\n",
    "    res = ... # 3. calculate the out_mean\n",
    "    print(res)\n",
    "    \n",
    "... #4. display the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ML we always try to optimize model parameters to minimize a loss function. TF allows for easy optimization problem solving.\n",
    "Let's see how this works. We will use a function $f$, parabolic with respect to the model parameter $t$: $f(x_1, x_2|t) = (x_1*t-x_2)^2$. Here $x_1$ and $x_2$ are given values for which we will try to minimize value of function $f$.\n",
    "\n",
    "We define `t` as a variable using `get_variable` and initialize it with a constant 0. Variables are by default trainable, *i.e.* their value will be changed during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "t = tf.get_variable(name='t', dtype=tf.float32, shape=(), initializer=tf.constant_initializer(0))\n",
    "x1 = tf.placeholder(name='x1', dtype=tf.float32, shape=())\n",
    "x2 = tf.placeholder(name='x2', dtype=tf.float32, shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to be minimized\n",
    "f = tf.square(t*x1-x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create and optimizer: object that on each iteration adjusts values of all trainable parameters (in our case just `t` to minimize the value of `f`. As the name sugests it uses steepest gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values of x1, x2 for which we will minimize f\n",
    "x1_val = 3.\n",
    "x2_val = 9.\n",
    "\n",
    "#buffers to store intermidiate values of t and f to plot them later.\n",
    "t_sv = []\n",
    "f_sv = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #don't forget to initialize all variables! \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #optimization works iteratively, adjusting the value of t on each step\n",
    "    for itr in range (30):\n",
    "        _ = sess.run(optimizer, feed_dict={x1:x1_val, x2:x2_val})\n",
    "        f_val, t_val = sess.run([f, t], feed_dict={x1:x1_val, x2:x2_val})\n",
    "        #save the current values of t and the function f\n",
    "        t_sv.append(t_val)\n",
    "        f_sv.append(f_val)\n",
    "        \n",
    "\n",
    "\n",
    "#just find the nice range for plotting\n",
    "x0 = x2_val/x1_val\n",
    "xhalf = max(abs(t_sv[0]-x0), 5.)\n",
    "#fill array for parabola\n",
    "t_all = np.arange(x0-xhalf, x0+xhalf, xhalf/50.)\n",
    "f_all = np.asarray([(ti*x1_val-x2_val)*(ti*x1_val-x2_val) for ti in t_all])\n",
    "\n",
    "#draw all\n",
    "_, axs = plt.subplots(1, 2, figsize=(10,10))\n",
    "axs[0].plot(t_all, f_all, 'b', t_sv, f_sv, 'g^')\n",
    "axs[0].set_title('f(t | x1,x2)')\n",
    "axs[0].legend(('f(t)', 'training iterations'),  loc='upper center')\n",
    "axs[1].plot(f_sv)\n",
    "axs[1].set_title('f(itr)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Excercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to modify ``x1_val`` and ``x2_val`` in the above code, as well as the ``learning_rate`` and ``t`` initialization value, and see how it affects convergence. Get an intuition on simple example, it is very useful!\n",
    "\n",
    "Try to see when \n",
    "1. convergence is too slow \n",
    "2. oscillation near minimum occurs\n",
    "3. divergence\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
